
# Sentiment Analysis on Product Reviews using BERT

This project leverages **BERT (Bidirectional Encoder Representations from Transformers)** to detect sentiment mismatches in product reviews based on their associated star ratings. It helps uncover **genuine vs non-genuine reviews** by comparing model-predicted sentiment with user-provided star ratings.

---

## ğŸ§  Project Objective

To build a fine-tuned BERT model that classifies sentiment (Positive, Negative, Neutral) of product reviews and flags **conflicts** where:

> The textual sentiment does **not align** with the numerical rating  
> (e.g., rating = â­1 but review = "Amazing product!")

---

## ğŸ“‚ Project Structure

```
BERT_MODEL/
â”œâ”€â”€ bert_sentiment_model/          # Final trained model + tokenizer
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”œâ”€â”€ special_tokens_map.json
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â””â”€â”€ vocab.txt
â”‚
â”œâ”€â”€ logs/                          # Training logs for TensorBoard
â”‚   â””â”€â”€ events.out.tfevents.*
â”‚
â”œâ”€â”€ results/checkpoint-1800/       # Intermediate checkpoint
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”œâ”€â”€ optimizer.pt
â”‚   â”œâ”€â”€ rng_state.pth
â”‚   â”œâ”€â”€ scheduler.pt
â”‚   â”œâ”€â”€ special_tokens_map.json
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â”œâ”€â”€ trainer_state.json
â”‚   â”œâ”€â”€ training_args.bin
â”‚   â””â”€â”€ vocab.txt
â”‚
â”œâ”€â”€ synthetic_reviews_dataset.xlsx # Dataset (reviews + ratings)
â”œâ”€â”€ sentiment_analysis_pipeline.py # Fine-tuning script for BERT
â””â”€â”€ testingModel.py                # Script to test and detect mismatches
```

---

## ğŸ“Š Dataset Format

The dataset is stored in `synthetic_reviews_dataset.xlsx` with the following columns:

| Customer Name | Review Title | Rating | Comment |
|---------------|---------------|--------|---------|

During preprocessing:
- **Comment** â†’ renamed to `review`
- **Rating** â†’ converted to `label`:  
  - `1` = Positive (rating â‰¥ 4)  
  - `0` = Negative (rating â‰¤ 2)  
  - `2` = Neutral (rating = 3)

---

## ğŸ”§ How to Train the Model

```bash
python sentiment_analysis_pipeline.py
```

This script:
- Loads the Excel dataset
- Preprocesses & tokenizes reviews using `bert-base-uncased`
- Fine-tunes a BERT model using Hugging Face's `Trainer`
- Saves model and tokenizer to `bert_sentiment_model/`

---

## ğŸ§ª How to Test & Detect Review Mismatches

```bash
python testingModel.py
```

This script:
- Loads the trained model and tokenizer
- Takes hardcoded reviews + ratings
- Predicts sentiment from review
- Compares with expected label derived from rating
- Logs any **conflicts** (e.g., positive review + low rating)

### Sample Output:
```
Review #1
     Review: Very good experience
     Rating: 1
     Predicted Sentiment: Positive
     Expected from Rating: Negative
     Conflict: YES
```

---

## ğŸ“¦ Dependencies

- `transformers`
- `datasets`
- `torch`
- `pandas`
- `openpyxl` (for reading Excel files)

Install all with:

```bash
pip install -r requirements.txt
```

> Create a `requirements.txt` if needed:

```txt
transformers
datasets
torch
pandas
openpyxl
```

---

## ğŸ“ˆ Applications

- Detect **fake or suspicious reviews**
- Improve **rating credibility**
- Automate **review moderation**
- Power intelligent **sentiment dashboards**

---

## ğŸ™Œ Contribution

Feel free to fork, improve, or extend the model with:
- Larger datasets
- Real-world review sources (Flipkart, Amazon, etc.)
- More granular sentiment (e.g., 5-class)

---

## ğŸ“© Contact

Made with â¤ï¸ by Utam Kumar(m23aid063@iitj.ac.in) 
- Open for collaborations or contributions!
